# コンピュータアーキテクチャII チートシート

---

## 1. パイプラインとハザード

パイプライン処理は、命令の実行を複数のステージ（IF, ID, EX, MEM, WB）に分割し、それらを並列に実行することでプロセッサのスループットを向上させる技術です 。

### 重要公式

* **パイプラインによるCPI (Cycles Per Instruction)**
    * n個の命令を5ステージパイプラインで実行する場合の理想的なCPIは、$CPI = \frac{n+4}{n} = 1 + \frac{4}{n}$ となる 。命令数が十分に大きい場合 ($n \to \infty$)、CPIは1に近づく 。

* **性能指標 MIPS (Million Instructions Per Second)**
    * $MIPS = \frac{クロック周波数 (MHz)}{CPI}$ 
    * $MIPS = クロック周波数 (MHz) \times IPC$  (※IPCはCPIの逆数)

### 基本用語

* **パイプラインステージ (Pipeline Stages)** 
    * **IF (Instruction Fetch)**: 命令フェッチ
    * **ID (Instruction Decode)**: 命令デコードとレジスタ読み出し
    * **EX (Execute)**: 演算実行
    * **MEM (Memory Access)**: メモリアクセス
    * **WB (Write Back)**: 結果のレジスタ書き込み

* **ハザード (Hazard)**: パイプラインの流れを乱し、性能を低下させる要因 。
    * **構造ハザード (Structural Hazard)**: ハードウェア資源の競合 。例えば、命令フェッチ（IF）とデータアクセス（MEM）が同時に単一ポートのメモリにアクセスしようとする場合 。
        * **解決策**: 命令キャッシュとデータキャッシュを分離する 。
    * **データハザード (Data Hazard)**: 後続の命令が、まだパイプライン内にある先行命令の実行結果を必要とする場合に発生する 。
        * **解決策**: **フォワーディング（バイパシング）**  で演算結果を後続ステージに直接渡す、または**ストール（バブル）**  を挿入して待機する。
    * **制御ハザード (Control Hazard)**: 分岐命令の実行結果（分岐するか否か）が確定するまで、次にどの命令をフェッチすればよいか分からない状態 。
        * **解決策**: **ストール** 、**分岐予測** 、**遅延分岐** 。

* **分岐予測 (Branch Prediction)**: 分岐命令の方向を予測し、投機的に命令実行を進める手法。
    * **動的分岐予測 (Dynamic Branch Prediction)**: 実行時の履歴に基づいて予測を行う 。
    * **分岐予測バッファ (Branch Prediction Buffer)**: 分岐命令のアドレスと過去の分岐結果（Taken/Not Taken）を保持するテーブル 。
    * **2bit飽和カウンタ (2-bit Saturating Counter)**: 4つの状態（Strongly Taken, Weakly Taken, Weakly Not Taken, Strongly Not Taken）を持ち、2回連続で予測が外れない限り予測を変更しないことで、ループの最後などで発生する一時的な分岐パターンの変化に強い 。

---

## 2. 記憶階層（キャッシュと仮想記憶）

プロセッサと主記憶の速度差（フォン・ノイマン・ボトルネック ）を埋めるため、高速・小容量のキャッシュメモリを階層的に用いる 。

### 重要公式

* **キャッシュミス発生時の実効CPI**
    * 基本CPIが1の場合、キャッシュミスによるペナルティを考慮したCPIは以下のように計算できる。
    * $CPI_{実効} = 1 + ミス率 \times ミスペナルティ$ 
        * ミスペナルティは、主記憶へのアクセス時間（クロックサイクル数） 。

### 主要アルゴリズム

* **LRU (Least Recently Used) ブロック置換アルゴリズム**: キャッシュがいっぱいの時に新しいブロックを入れる際、最も長い間アクセスされていないブロックを追い出す方式 。時間的局所性の原理に基づく 。

### 基本用語

* **時間的局所性 (Temporal Locality)**: 一度アクセスされたデータは、近い将来再びアクセスされる可能性が高い 。
* **空間的局所性 (Spatial Locality)**: あるデータがアクセスされた場合、その近傍のデータもアクセスされる可能性が高い 。
* **キャッシュマッピング方式 (Cache Mapping)**
    * **ダイレクトマップ (Direct Mapped)**: 主記憶の各ブロックがキャッシュ内の特定の1つのラインにのみ配置される方式 。回路は単純だが、コンフリクトミス（スラッシング ）が起きやすい。
    * **フルアソシアティブ (Fully Associative)**: 主記憶のどのブロックもキャッシュ内のどのラインにでも配置できる方式 。ヒット率は高いが、全てのタグを比較する必要があり回路規模が大きく複雑になる 。
    * **nウェイ・セットアソシアティブ (n-way Set-Associative)**: 上記2つの中間。キャッシュを複数のセットに分割し、各セット内ではn個のブロックを自由に配置できる 。
* **書き込み方針 (Write Policy)**
    * **ライトスルー (Write-Through)**: CPUが書き込みを行う際、キャッシュと主記憶の両方を同時に更新する 。
    * **ライトバック (Write-Back)**: 書き込みはまずキャッシュに対してのみ行い、そのブロックがキャッシュから追い出される時に初めて主記憶に書き戻す 。
* **仮想記憶 (Virtual Memory)**: 二次記憶装置を利用して、主記憶の物理容量よりも大きなアドレス空間をプロセスに提供する仕組み 。
* **ページング (Paging)**: 仮想アドレス空間と物理アドレス空間を**ページ**という固定長のブロックに分割して管理する方式 。
* **ページテーブル (Page Table)**: 仮想ページ番号と物理ページフレーム番号の対応関係を格納するテーブル 。
* **TLB (Translation Lookaside Buffer)**: ページテーブルのエントリをキャッシュするための高速な連想メモリ。アドレス変換を高速化する 。
* **セグメンテーション (Segmentation)**: プログラムをコード、データ、スタックといった論理的な**セグメント**に分割して管理する方式 。

---

## 3. 命令レベル並列性 (ILP)

パイプラインを複数用意し、依存関係のない命令を同時に実行することで性能を向上させる技術 。性能指標としてCPI (<1) の代わりに**IPC (Instructions Per Cycle)**が用いられる 。

### 基本用語

* **VLIW (Very Long Instruction Word)**: コンパイラが静的に依存関係を解析し、同時に実行可能な複数の命令を1つの長い命令（VLIW）にまとめるアーキテクチャ 。ハードウェアは単純だが、バイナリ互換性に問題がある 。
* **スーパースカラ (Superscalar)**: ハードウェアが動的に命令間の依存関係を解析し、複数の命令を並列に実行するアーキテクチャ 。バイナリ互換性を保ちやすいが、ハードウェアが複雑になる 。
  * **Out-of-Order実行**: 依存関係がなければ、プログラム上の命令の順序とは異なる順序で命令を実行する 。
* **データ依存の種類**
  * **フロー依存 (真の依存)**: Read-After-Write (RAW)。先行命令の書き込み結果を後続命令が読み出す。この順序は変更不可 。
  * **逆依存 (偽の依存)**: Write-After-Read (WAR)。先行命令が読み出したレジスタを後続命令が上書きする 。
  * **出力依存 (偽の依存)**: Write-After-Write (WAW)。先行命令と後続命令が同じレジスタに書き込む 。
* **レジスタリネーミング (Register Renaming)**: 偽の依存関係（逆依存、出力依存）を、物理的に多数あるレジスタを割り当てることで動的に解消し、並列性を高める技術 。

---

## 4. データ並列とマルチプロセッサ

### 基本用語

* **データ並列性 (Data Parallelism)**: 複数のデータに対して同じ処理を並列に実行できる性質 。
* **SIMD (Single Instruction, Multiple Data)**: 1つの命令で複数のデータを同時に処理するアーキテクチャまたは命令セット（例: MMX, SSE, AVX）。
* **共有メモリ型マルチプロセッサ**: 複数のプロセッサが単一のアドレス空間を共有するシステム 。
  * **UMA (Uniform Memory Access)**: どのプロセッサからも全てのメモリ領域に同じ時間でアクセスできる 。
  * **NUMA (Non-Uniform Memory Access)**: プロセッサとメモリの物理的な位置関係によってメモリアクセス時間が異なる 。
* **キャッシュコヒーレンシ (Cache Coherency)**: マルチプロセッサシステムにおいて、各プロセッサが持つキャッシュの内容と主記憶の内容との整合性を保つこと 。
* **スヌーピング (Snooping)**: 各キャッシュが共有バスを監視（スヌープ）し、他のプロセッサのメモリアクセスを検知して自身のキャッシュの状態を更新（または無効化）する手法 。
* **ディレクトリ方式 (Directory-based Protocol)**: 大規模な分散共有メモリシステムで用いられる。各メモリブロックの共有状態（どのプロセッサがコピーを持っているか）をディレクトリで一元管理する 。